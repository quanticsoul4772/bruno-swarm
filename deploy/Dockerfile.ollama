# Bruno Swarm — All 7 agent models pre-baked into Ollama
#
# Two-stage build:
#   1. builder  — Ollama + Python: downloads GGUFs, imports into Ollama, cleans up
#   2. runtime  — Clean Ollama image with only /root/.ollama blobs
#
# Build:  docker build -f deploy/Dockerfile.ollama -t bruno-swarm-ollama .
# Run:    docker run --gpus all -p 11434:11434 bruno-swarm-ollama

# ===== Stage 1: Download GGUFs and import into Ollama =====
FROM ollama/ollama AS builder

# Install Python + huggingface-hub (temporary, not in final image)
RUN apt-get update && \
    apt-get install -y --no-install-recommends python3 python3-pip && \
    pip3 install --no-cache-dir --break-system-packages huggingface-hub && \
    apt-get clean && rm -rf /var/lib/apt/lists/*

COPY deploy/download-and-prepare.py /app/download-and-prepare.py

# Download models and generate Modelfiles
RUN python3 /app/download-and-prepare.py

# Import models into Ollama, then clean up
RUN bash -c 'ollama serve & SERVER_PID=$! && \
    for i in $(seq 1 30); do \
        ollama list >/dev/null 2>&1 && break; \
        if [ "$i" -eq 30 ]; then echo "ERROR: Ollama failed to start"; exit 1; fi; \
        sleep 1; \
    done && \
    echo "=== Creating models ===" && \
    ollama create orchestrator -f /tmp/modelfiles/Modelfile.orchestrator && \
    ollama create frontend -f /tmp/modelfiles/Modelfile.frontend && \
    ollama create backend -f /tmp/modelfiles/Modelfile.backend && \
    ollama create test -f /tmp/modelfiles/Modelfile.test && \
    ollama create security -f /tmp/modelfiles/Modelfile.security && \
    ollama create docs -f /tmp/modelfiles/Modelfile.docs && \
    ollama create devops -f /tmp/modelfiles/Modelfile.devops && \
    echo "=== Models created ===" && \
    ollama list && \
    kill $SERVER_PID && \
    wait $SERVER_PID 2>/dev/null' && \
    rm -rf /tmp/models /tmp/modelfiles /app && \
    apt-get purge -y python3 python3-pip && \
    apt-get autoremove -y && \
    rm -rf /var/lib/apt/lists/*

# ===== Stage 2: Clean runtime image =====
FROM ollama/ollama AS runtime

LABEL org.opencontainers.image.title="Bruno Swarm Ollama" \
      org.opencontainers.image.description="7 specialized coding agents (1x 14B orchestrator + 6x 3B specialists) pre-loaded in Ollama" \
      org.opencontainers.image.source="https://github.com/quanticsoul4772/bruno-swarm" \
      org.opencontainers.image.licenses="AGPL-3.0-or-later"

COPY --from=builder /root/.ollama /root/.ollama

COPY deploy/docker-entrypoint.sh /docker-entrypoint.sh
RUN sed -i 's/\r$//' /docker-entrypoint.sh && chmod +x /docker-entrypoint.sh

ENV OLLAMA_HOST=0.0.0.0
ENV OLLAMA_MAX_LOADED_MODELS=3
ENV OLLAMA_KEEP_ALIVE=30m

EXPOSE 11434

ENTRYPOINT ["/docker-entrypoint.sh"]
CMD ["serve"]
